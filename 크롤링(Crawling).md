크롤링(Crawling)
--------------------------------------------
- 검색 엔진 봇(예: 구글봇)이 웹 페이지를 자동으로 방문해서 웹 페이지의 내용을 읽고 저장하는 과정을 크롤링이라고 합니다.
- 크롤링을 통해 검색엔진은 해당 웹 페이지를 인덱스에 추가하고, 이러한 크롤링을 거쳐서 웹 페이지가 검색 결과에 노출이 되게 됩니다.

크롤링을 설정하는 robots.txt 파일
--------------------------------------------
- robots.txt 파일을 통해 '특정 웹 사이트에서 자신의 크롤러가 크롤링할 방식'을 설정할 수 있습니다. 
- 보통 자동으로 생성되지는 않으며, 텍스트 편집기등을 통해서 생성합니다.
- 항상 위치한다면 웹 사이트의 루트 디렉토리에 위치해야 합니다.

![image](https://github.com/user-attachments/assets/f41c2682-b425-4133-87fd-90f03b521692)
